import sqlite3
import json
from datetime import datetime
import os
import logging
import requests
import asyncio
import time
import re
import random
import signal
import sys
import aiohttp
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
from datetime import datetime, timedelta
from telegram import Update
from telegram.ext import Application, MessageHandler, filters, ContextTypes, CommandHandler, CallbackContext
from telegram.error import Conflict
from enum import Enum
from collections import deque, defaultdict
import numpy as np
import humanize
from dateutil import parser
import uuid
from typing import Dict, Any, List, Optional
import hashlib
import json

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è graceful shutdown
def signal_handler(sig, frame):
    print("\nüõë –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –±–æ—Ç–∞...")
    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É –¥–ª—è graceful shutdown
    if 'application' in globals() and application.running:
        application.stop()
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# –í–∞—à–∏ –∫–ª—é—á–∏
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
YANDEX_API_KEY = os.getenv("YANDEX_API_KEY")
YANDEX_FOLDER_ID = os.getenv("YANDEX_FOLDER_ID")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ—á—Ç—ã
EMAIL_HOST = os.getenv("EMAIL_HOST", "smtp.yandex.ru")
EMAIL_PORT = int(os.getenv("EMAIL_PORT", 587))
EMAIL_USER = os.getenv("EMAIL_USER", "ziminleks@yandex.ru")
EMAIL_PASSWORD = os.getenv("EMAIL_PASSWORD")
EMAIL_TO = os.getenv("EMAIL_TO", "ziminleks@yandex.ru")

# URL API Yandex GPT
YANDEX_API_URL = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"

# –ö–æ–Ω—Ç–µ–∫—Å—Ç –±–µ—Å–µ–¥—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
conversation_context = {}

class DeepContextAnalyzer:
    """–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –±–µ—Å–µ–¥—ã"""
    
    def __init__(self):
        self.topic_memory = defaultdict(lambda: {'count': 0, 'last_mentioned': None, 'sentiment': 0.5})
        self.conversation_flow = deque(maxlen=10)
        
    def extract_deep_context(self, message, history, user_context):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–ª—É–±–æ–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –≤—Å–µ–π –±–µ—Å–µ–¥—ã"""
        context = {
            'current_topics': self._extract_topics(message),
            'historical_topics': self._analyze_historical_topics(history),
            'emotional_arc': self._analyze_emotional_arc(history),
            'conversation_rhythm': self._analyze_conversation_rhythm(history),
            'unfinished_threads': self._find_unfinished_threads(history),
            'user_patterns': self._analyze_user_patterns(history, user_context)
        }
        return context
    
    def _extract_topics(self, text):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º —Å –≤–µ—Å–∞–º–∏"""
        words = re.findall(r'\b[–∞-—è—ë]{3,}\b', text.lower())
        stop_words = {'—ç—Ç–æ—Ç', '–æ—á–µ–Ω—å', '–∫–æ—Ç–æ—Ä—ã–π', '–∫–æ–≥–¥–∞', '–ø–æ—Ç–æ–º', '—Ç–æ–≥–¥–∞', '–≤–æ–æ–±—â–µ', '–∑–Ω–∞—á–∏—Ç'}
        topics = {}
        
        for word in set(words) - stop_words:
            if len(word) > 2:
                # –í–µ—Å based on —á–∞—Å—Ç–æ—Ç–µ –∏ –ø–æ–∑–∏—Ü–∏–∏
                weight = words.count(word) * 0.3
                if word in text[:50]:  # –£–ø–æ–º–∏–Ω–∞–Ω–∏–µ –≤ –Ω–∞—á–∞–ª–µ
                    weight += 0.2
                topics[word] = min(1.0, weight)
        
        return dict(sorted(topics.items(), key=lambda x: x[1], reverse=True)[:5])
    
    def _analyze_historical_topics(self, history):
        """–ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Ç–µ–º"""
        historical_topics = {}
        for i, msg in enumerate(history[-20:]):  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å–æ–æ–±—â–µ–Ω–∏–π
            if 'user' in msg:
                topics = self._extract_topics(msg['user'])
                for topic, weight in topics.items():
                    if topic in historical_topics:
                        historical_topics[topic] += weight * (0.9 ** i)  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ
                    else:
                        historical_topics[topic] = weight * (0.9 ** i)
        
        return dict(sorted(historical_topics.items(), key=lambda x: x[1], reverse=True)[:8])
    
    def _analyze_emotional_arc(self, history):
        """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –¥—É–≥–∏ –±–µ—Å–µ–¥—ã"""
        emotions = []
        for msg in history[-10:]:
            if 'user' in msg:
                emotional_score = self._calculate_emotional_score(msg['user'])
                emotions.append(emotional_score)
        
        if len(emotions) > 2:
            trend = np.polyfit(range(len(emotions)), emotions, 1)[0]
            return {
                'current_mood': emotions[-1] if emotions else 0.5,
                'trend': trend,
                'volatility': np.std(emotions) if len(emotions) > 1 else 0
            }
        return {'current_mood': 0.5, 'trend': 0, 'volatility': 0}
    
    def _calculate_emotional_score(self, text):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–∫–æ—Ä–∞"""
        positive = sum(1 for word in ['—Ä–∞–¥', '—Å—á–∞—Å—Ç–ª–∏–≤', '—Ö–æ—Ä–æ—à–æ', '–æ—Ç–ª–∏—á–Ω–æ', '–ª—é–±–ª—é'] if word in text.lower())
        negative = sum(1 for word in ['–≥—Ä—É—Å—Ç–Ω–æ', '–ø–ª–æ—Ö–æ', '–Ω–µ–Ω–∞–≤–∏–∂—É', '–∑–ª–æ–π', '–æ–±–∏–¥–Ω–æ'] if word in text.lower())
        
        total = positive + negative
        if total == 0:
            return 0.5
        return positive / total
    
    def _analyze_conversation_rhythm(self, history):
        """–ê–Ω–∞–ª–∏–∑ —Ä–∏—Ç–º–∞ –±–µ—Å–µ–¥—ã"""
        if len(history) < 3:
            return {'pace': 'medium', 'initiative': 0.5}
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–µ–º–ø–∞
        response_times = []
        for i in range(1, min(10, len(history))):
            if 'timestamp' in history[i] and 'timestamp' in history[i-1]:
                delta = (history[i]['timestamp'] - history[i-1]['timestamp']).total_seconds()
                response_times.append(delta)
        
        avg_response = np.mean(response_times) if response_times else 60
        if avg_response < 30:
            pace = 'fast'
        elif avg_response < 120:
            pace = 'medium'
        else:
            pace = 'slow'
        
        # –ê–Ω–∞–ª–∏–∑ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã
        user_messages = sum(1 for msg in history[-10:] if 'user' in msg)
        initiative = user_messages / min(10, len(history))
        
        return {'pace': pace, 'initiative': initiative}
    
    def _find_unfinished_threads(self, history):
        """–ü–æ–∏—Å–∫ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö —Ç–µ–º"""
        unfinished = []
        questions = []
        
        for msg in history[-10:]:
            if 'user' in msg and '?' in msg['user']:
                questions.append(msg['user'])
            if 'bot' in msg and '?' in msg['bot']:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –±–æ—Ç–∞
                next_msgs = history[history.index(msg)+1:]
                if not any('user' in m and '?' not in m.get('user', '') for m in next_msgs[:2]):
                    unfinished.append(msg['bot'])
        
        return {'user_questions': questions[-3:], 'bot_questions': unfinished}
    
    def _analyze_user_patterns(self, history, user_context):
        """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        patterns = {
            'question_frequency': 0,
            'emotional_consistency': 0,
            'topic_persistence': 0,
            'response_style': 'balanced'
        }
        
        if len(history) < 5:
            return patterns
        
        # –ß–∞—Å—Ç–æ—Ç–∞ –≤–æ–ø—Ä–æ—Å–æ–≤
        questions = sum(1 for msg in history[-10:] if 'user' in msg and '?' in msg['user'])
        patterns['question_frequency'] = questions / min(10, len(history))
        
        # –°—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–æ–≤
        message_lengths = [len(msg.get('user', '')) for msg in history[-10:] if 'user' in msg]
        if message_lengths:
            avg_length = np.mean(message_lengths)
            patterns['response_style'] = 'detailed' if avg_length > 50 else 'concise'
        
        return patterns

class HumanConversationSimulator:
    """–°–∏–º—É–ª—è—Ç–æ—Ä —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π –±–µ—Å–µ–¥—ã"""
    
    def __init__(self):
        self.typing_profiles = self._create_typing_profiles()
        self.conversation_styles = self._create_conversation_styles()
        self.memory_system = MemorySystem()
        
    def _create_typing_profiles(self):
        """–ü—Ä–æ—Ñ–∏–ª–∏ –ø–µ—á–∞—Ç–∞–Ω–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ª–∏—á–Ω–æ—Å—Ç–∏"""
        return {
            'fast': {'base_speed': 0.02, 'variation': 0.7, 'error_rate': 0.005},
            'normal': {'base_speed': 0.03, 'variation': 0.8, 'error_rate': 0.01},
            'thoughtful': {'base_speed': 0.04, 'variation': 0.9, 'error_rate': 0.015},
            'emotional': {'base_speed': 0.025, 'variation': 1.2, 'error_rate': 0.02}
        }
    
    def _create_conversation_styles(self):
        """–°—Ç–∏–ª–∏ –≤–µ–¥–µ–Ω–∏—è –±–µ—Å–µ–¥—ã"""
        return {
            'active': {'question_rate': 0.4, 'topic_change': 0.3, 'detail_level': 0.8},
            'reactive': {'question_rate': 0.2, 'topic_change': 0.1, 'detail_level': 0.6},
            'balanced': {'question_rate': 0.3, 'topic_change': 0.2, 'detail_level': 0.7},
            'deep': {'question_rate': 0.25, 'topic_change': 0.15, 'detail_level': 0.9}
        }
    
    async def simulate_human_response(self, message, context, history):
        """–°–∏–º—É–ª—è—Ü–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
        # –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        deep_context = context['deep_context']
        
        # –í—ã–±–æ—Ä —Å—Ç–∏–ª—è based on –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        conversation_style = self._select_conversation_style(deep_context)
        typing_profile = self._select_typing_profile(deep_context)
        
        # –í—Ä–µ–º—è –Ω–∞ –æ–±–¥—É–º—ã–≤–∞–Ω–∏–µ
        thinking_time = self._calculate_thinking_time(message, deep_context, history)
        if thinking_time > 0.5:
            await asyncio.sleep(thinking_time)
        
        # –ò–º–∏—Ç–∞—Ü–∏—è –ø–µ—á–∞—Ç–∞–Ω–∏—è
        typing_time = self._calculate_typing_time(message, typing_profile, context)
        await asyncio.sleep(typing_time)
        
        return {
            'thinking_time': thinking_time,
            'typing_time': typing_time,
            'conversation_style': conversation_style,
            'typing_profile': typing_profile
        }
    
    def _select_conversation_style(self, deep_context):
        """–í—ã–±–æ—Ä —Å—Ç–∏–ª—è –±–µ—Å–µ–¥—ã based on –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        mood = deep_context['emotional_arc']['current_mood']
        pace = deep_context['conversation_rhythm']['pace']
        
        if mood > 0.7 and pace == 'fast':
            return 'active'
        elif mood < 0.3:
            return 'reactive'
        elif deep_context['user_patterns']['response_style'] == 'detailed':
            return 'deep'
        else:
            return 'balanced'
    
    def _select_typing_profile(self, deep_context):
        """–í—ã–±–æ—Ä –ø—Ä–æ—Ñ–∏–ª—è –ø–µ—á–∞—Ç–∞–Ω–∏—è"""
        volatility = deep_context['emotional_arc']['volatility']
        if volatility > 0.3:
            return 'emotional'
        elif deep_context['conversation_rhythm']['pace'] == 'fast':
            return 'fast'
        else:
            return random.choice(['normal', 'thoughtful'])
    
    def _calculate_thinking_time(self, message, deep_context, history):
        """–í—Ä–µ–º—è –Ω–∞ –æ–±–¥—É–º—ã–≤–∞–Ω–∏–µ"""
        base_time = random.uniform(0.5, 2.0)
        
        # –ú–Ω–æ–∂–∏—Ç–µ–ª–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        complexity = 1.0
        if '?' in message:
            complexity += 0.5
        if len(message) > 100:
            complexity += 0.3
        if deep_context['emotional_arc']['volatility'] > 0.2:
            complexity += 0.4
        
        # –£—á–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏
        if len(history) > 5:
            recent_emotional = [m for m in history[-3:] if 'emotional_score' in m]
            if recent_emotional and any(m['emotional_score'] < 0.3 for m in recent_emotional):
                complexity += 0.5
        
        return base_time * complexity
    
    def _calculate_typing_time(self, message, profile, context):
        """–í—Ä–µ–º—è –ø–µ—á–∞—Ç–∞–Ω–∏—è"""
        profile_config = self.typing_profiles[profile]
        base_time = len(message) * profile_config['base_speed']
        
        # –í–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å
        variation = random.uniform(1 - profile_config['variation'], 
                                 1 + profile_config['variation'])
        
        # –û–ø—ã—Ç –æ–±—â–µ–Ω–∏—è (—Å–æ –≤—Ä–µ–º–µ–Ω–µ–º –ø–µ—á–∞—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–µ–µ)
        experience = max(0.7, 1.0 - (context.get('messages_count', 0) * 0.0005))
        
        return base_time * variation * experience

class MemorySystem:
    """–°–∏—Å—Ç–µ–º–∞ –ø–∞–º—è—Ç–∏ –∏ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
    
    def __init__(self):
        self.long_term_memory = {}
        self.associative_triggers = self._create_associative_triggers()
    
    def _create_associative_triggers(self):
        """–ê—Å—Å–æ—Ü–∏–∞—Ç–∏–≤–Ω—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã –¥–ª—è –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
        return {
            'time_based': {
                'today': "–ö—Å—Ç–∞—Ç–∏, –ø–æ–º–Ω–∏—à—å —Å–µ–≥–æ–¥–Ω—è –º—ã –≥–æ–≤–æ—Ä–∏–ª–∏ –æ {}?",
                'recent': "–í—Å–ø–æ–º–Ω–∏–ª –Ω–∞—à –Ω–µ–¥–∞–≤–Ω–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä –ø—Ä–æ {}",
                'past': "–û, –¥–∞–≤–Ω–æ –º—ã –Ω–µ –≤—Å–ø–æ–º–∏–Ω–∞–ª–∏ –æ {}"
            },
            'topic_based': {
                'strong': "–ì–æ–≤–æ—Ä—è –æ {}, –Ω–µ –º–æ–≥—É –Ω–µ –≤—Å–ø–æ–º–Ω–∏—Ç—å...",
                'medium': "–≠—Ç–æ –Ω–∞–ø–æ–º–∏–Ω–∞–µ—Ç –º–Ω–µ –æ {}",
                'weak': "–ö—Å—Ç–∞—Ç–∏, –æ {}..."
            },
            'emotional': {
                'positive': "–í—Å–ø–æ–º–Ω–∏–ª–æ—Å—å –∫–∞–∫ –º—ã –≤–µ—Å–µ–ª–æ –æ–±—Å—É–∂–¥–∞–ª–∏ {}",
                'negative': "–ü–æ–º–Ω–∏—à—å —Ç–æ—Ç —Å–ª–æ–∂–Ω—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä –æ {}?",
                'neutral': "–ü—Ä–∏—à–ª–æ –Ω–∞ —É–º –Ω–∞—à–µ –æ–±—Å—É–∂–¥–µ–Ω–∏–µ {}"
            }
        }
    
    def create_contextual_memory(self, current_message, history, user_context):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
        if len(history) < 3:
            return None
        
        current_topics = set(DeepContextAnalyzer()._extract_topics(current_message).keys())
        memory_candidates = []
        
        # –ü–æ–∏—Å–∫ –≤ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ —Ç–µ–º–∞–º
        for i, past_msg in enumerate(history[-20:]):
            if 'user' in past_msg:
                past_topics = set(DeepContextAnalyzer()._extract_topics(past_msg['user']).keys())
                common_topics = current_topics.intersection(past_topics)
                
                if common_topics:
                    days_ago = (datetime.now() - past_msg.get('timestamp', datetime.now())).days
                    memory_candidates.append({
                        'topics': common_topics,
                        'recency': days_ago,
                        'message': past_msg['user'],
                        'index': i
                    })
        
        if not memory_candidates:
            return None
        
        # –í—ã–±–æ—Ä –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è
        best_memory = max(memory_candidates, key=lambda x: (
            len(x['topics']) * 0.5 + 
            (1 / (x['recency'] + 1)) * 0.3 +
            random.random() * 0.2
        ))
        
        topic = random.choice(list(best_memory['topics']))
        return self._format_memory_reference(topic, best_memory['recency'])
    
    def _format_memory_reference(self, topic, days_ago):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ"""
        if days_ago == 0:
            time_key = 'today'
        elif days_ago <= 3:
            time_key = 'recent'
        else:
            time_key = 'past'
        
        # –°–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä —Ç–∏–ø–∞ —Å—Å—ã–ª–∫–∏
        memory_type = random.choice(['time_based', 'topic_based', 'emotional'])
        intensity = random.choice(['strong', 'medium', 'weak'])
        
        template = self.associative_triggers[memory_type].get(
            intensity, 
            self.associative_triggers[memory_type]['medium']
        )
        
        return template.format(topic)

class EmotionalIntelligence:
    """–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"""
    
    def __init__(self):
        self.emotional_models = self._create_emotional_models()
        self.empathy_responses = self._create_empathy_responses()
    
    def analyze_emotional_state(self, message, history):
        """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
        text = message.lower()
        
        # –ë–∞–∑–æ–≤—ã–π —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        emotions = {
            'joy': self._detect_emotion(text, ['—Ä–∞–¥', '—Å—á–∞—Å—Ç–ª–∏–≤', '—É—Ä–∞', '–∫–ª–∞—Å—Å', '—Å—É–ø–µ—Ä']),
            'sadness': self._detect_emotion(text, ['–≥—Ä—É—Å—Ç–Ω–æ', '–ø–µ—á–∞–ª—å–Ω–æ', '–ø–ª–æ—Ö–æ', '—Ç—è–∂–µ–ª–æ']),
            'anger': self._detect_emotion(text, ['–∑–ª–æ–π', '—Å–µ—Ä–¥–∏—Ç', '–±–µ—Å–∏—Ç', '–Ω–µ–Ω–∞–≤–∏–∂—É']),
            'excitement': self._detect_emotion(text, ['!', '!!', '!!!', '–≤–∞—É', '–æ–≥–æ']),
            'confusion': self._detect_emotion(text, ['?', '??', '???', '–Ω–µ –ø–æ–Ω–∏–º–∞—é', '–∑–∞–ø—É—Ç–∞–ª—Å—è'])
        }
        
        # –ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –¥—É–≥–∏
        emotional_trend = self._analyze_emotional_trend(history)
        
        return {
            'current_emotions': emotions,
            'dominant_emotion': max(emotions.items(), key=lambda x: x[1])[0],
            'emotional_trend': emotional_trend,
            'intensity': max(emotions.values()) if emotions else 0
        }
    
    def _detect_emotion(self, text, triggers):
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —ç–º–æ—Ü–∏–∏"""
        score = 0
        for trigger in triggers:
            if trigger in text:
                score += 1
        return min(1.0, score * 0.3)
    
    def _analyze_emotional_trend(self, history):
        """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞"""
        if len(history) < 3:
            return 'stable'
        
        recent_scores = []
        for msg in history[-5:]:
            if 'user' in msg:
                score = self._calculate_emotional_score(msg['user'])
                recent_scores.append(score)
        
        if len(recent_scores) > 2:
            trend = np.polyfit(range(len(recent_scores)), recent_scores, 1)[0]
            if abs(trend) > 0.1:
                return 'improving' if trend > 0 else 'worsening'
        return 'stable'
    
    def _calculate_emotional_score(self, text):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–∫–æ—Ä–∞"""
        positive = sum(1 for word in ['—Ä–∞–¥', '—Å—á–∞—Å—Ç–ª–∏–≤', '—Ö–æ—Ä–æ—à–æ', '–æ—Ç–ª–∏—á–Ω–æ'] if word in text.lower())
        negative = sum(1 for word in ['–≥—Ä—É—Å—Ç–Ω–æ', '–ø–ª–æ—Ö–æ', '–Ω–µ–Ω–∞–≤–∏–∂—É', '–∑–ª–æ–π'] if word in text.lower())
        
        total = positive + negative + 0.001  # –∏–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
        return positive / total
    
    def generate_empathic_response(self, emotional_state, response):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–ø–∞—Ç–∏—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
        dominant = emotional_state['dominant_emotion']
        intensity = emotional_state['intensity']
        
        if intensity > 0.3:
            # –î–æ–±–∞–≤–ª—è–µ–º —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é —Ä–µ–∞–∫—Ü–∏—é
            emotional_reaction = self._get_emotional_reaction(dominant, intensity)
            if random.random() < 0.6:
                response = f"{emotional_reaction} {response}"
            
            # –î–æ–±–∞–≤–ª—è–µ–º —ç–º–ø–∞—Ç–∏—á–Ω—É—é —Ñ—Ä–∞–∑—É
            if random.random() < 0.4:
                empathic_phrase = self._get_empathic_phrase(dominant, intensity)
                response = f"{response} {empathic_phrase}"
        
        return response
    
    def _get_emotional_reaction(self, emotion, intensity):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ä–µ–∞–∫—Ü–∏–∏"""
        reactions = {
            'joy': ['üòä', 'üéâ', '‚ú®', 'ü•≥'],
            'sadness': ['üòî', 'ü§ó', '‚ù§Ô∏è', 'üíî'],
            'anger': ['üò†', 'üò§', 'üí¢', '‚ö°'],
            'excitement': ['üòÉ', 'üöÄ', 'üåü', 'üî•'],
            'confusion': ['ü§î', 'üòï', 'üßê', 'üí≠']
        }
        return random.choice(reactions.get(emotion, ['üôÇ']))
    
    def _get_empathic_phrase(self, emotion, intensity):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–ø–∞—Ç–∏—á–Ω–æ–π —Ñ—Ä–∞–∑—ã"""
        phrases = {
            'joy': ['–Ø —Ä–∞–¥ –∑–∞ —Ç–µ–±—è!', '–≠—Ç–æ –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ!', '–ö–∞–∫ –∑–¥–æ—Ä–æ–≤–æ!'],
            'sadness': ['–ü–æ–Ω–∏–º–∞—é —Ç–µ–±—è...', '–ú–Ω–µ –∂–∞–ª—å...', '–î–µ—Ä–∂–∏—Å—å!'],
            'anger': ['–ü–æ–Ω–∏–º–∞—é —Ç–≤–æ–∏ —á—É–≤—Å—Ç–≤–∞', '–≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –Ω–µ–ø—Ä–∏—è—Ç–Ω–æ'],
            'excitement': ['–ó–¥–æ—Ä–æ–≤–æ!', '–í–æ—Å—Ö–∏—Ç–∏—Ç–µ–ª—å–Ω–æ!', '–Ø —Ä–∞–∑–¥–µ–ª—è—é —Ç–≤–æ–π –≤–æ—Å—Ç–æ—Ä–≥!'],
            'confusion': ['–ü–æ–Ω–∏–º–∞—é —Ç–≤–æ—ë –∑–∞–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–æ', '–î–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä–µ–º—Å—è –≤–º–µ—Å—Ç–µ']
        }
        return random.choice(phrases.get(emotion, ['–ü–æ–Ω–∏–º–∞—é...']))

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —ç–∫–∑–µ–º–ø–ª—è—Ä—ã
context_analyzer = DeepContextAnalyzer()
conversation_simulator = HumanConversationSimulator()
memory_system = MemorySystem()
emotional_intelligence = EmotionalIntelligence()

def get_user_context(user_id: int) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    try:
        conn = sqlite3.connect("bot_users.db")
        cursor = conn.cursor()
        
        # –ü–æ–ª—É—á–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
        cursor.execute("SELECT * FROM users WHERE user_id = ?", (user_id,))
        user_data = cursor.fetchone()
        
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
        cursor.execute("""
            SELECT message_text, bot_response, timestamp, emotional_score, topic_tags 
            FROM messages 
            WHERE user_id = ? 
            ORDER BY timestamp DESC 
            LIMIT 20
        """, (user_id,))
        messages = cursor.fetchall()
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–µ—Å–µ–¥—ã
        cursor.execute("SELECT * FROM conversation_context WHERE user_id = ?", (user_id,))
        context_data = cursor.fetchone()
        
        conn.close()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = {
            'user_id': user_id,
            'history': [],
            'messages_count': 0,
            'last_interaction': None
        }
        
        if user_data:
            context['messages_count'] = user_data[6] if len(user_data) > 6 else 0
            context['last_interaction'] = user_data[5] if len(user_data) > 5 else None
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
        for msg in messages:
            context['history'].append({
                'user': msg[0],
                'bot': msg[1],
                'timestamp': datetime.fromisoformat(msg[2]) if isinstance(msg[2], str) else msg[2],
                'emotional_score': msg[3],
                'topics': json.loads(msg[4]) if msg[4] else []
            })
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if context_data:
            try:
                context['deep_context'] = {
                    'current_topics': json.loads(context_data[1]) if context_data[1] else {},
                    'historical_topics': json.loads(context_data[2]) if context_data[2] else {},
                    'emotional_arc': json.loads(context_data[3]) if context_data[3] else {},
                    'conversation_rhythm': json.loads(context_data[4]) if context_data[4] else {},
                    'user_patterns': json.loads(context_data[5]) if context_data[5] else {},
                    'unfinished_threads': json.loads(context_data[6]) if context_data[6] else {}
                }
            except json.JSONDecodeError:
                context['deep_context'] = {}
        
        return context
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        return {'user_id': user_id, 'history': [], 'messages_count': 0}

def save_complete_context(user_id: int, user_message: str, bot_response: str, 
                         deep_context: Dict[str, Any], emotional_state: Dict[str, Any],
                         response_metrics: Dict[str, Any], memory_reference: Optional[str] = None):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –±–µ—Å–µ–¥—ã"""
    try:
        conn = sqlite3.connect("bot_users.db")
        cursor = conn.cursor()
        
        # –°–æ–∑–¥–∞–µ–º —Ö—ç—à –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
        context_hash = hashlib.md5(
            f"{user_id}{user_message}{datetime.now().timestamp()}".encode()
        ).hexdigest()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–º—ã –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è
        topics = list(deep_context.get('current_topics', {}).keys())[:5]
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        cursor.execute("""
            INSERT OR IGNORE INTO users (user_id, created_at, last_interaction) 
            VALUES (?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
        """, (user_id,))
        
        cursor.execute("""
            UPDATE users SET last_interaction = CURRENT_TIMESTAMP WHERE user_id = ?
        """, (user_id,))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        cursor.execute("""
            INSERT INTO messages 
            (user_id, message_text, bot_response, message_type, emotions, style, 
             typing_time, thinking_time, context_hash, emotional_score, topic_tags)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            user_id, 
            user_message, 
            bot_response,
            'text',
            json.dumps(emotional_state),
            response_metrics.get('conversation_style', 'balanced'),
            response_metrics.get('typing_time', 0),
            response_metrics.get('thinking_time', 0),
            context_hash,
            emotional_state.get('intensity', 0.5),
            json.dumps(topics)
        ))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–µ—Å–µ–¥—ã
        cursor.execute("""
            INSERT OR REPLACE INTO conversation_context 
            (user_id, current_topics, historical_topics, emotional_arc, 
             conversation_rhythm, user_patterns, unfinished_threads, last_deep_analysis)
            VALUES (?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
        """, (
            user_id,
            json.dumps(deep_context.get('current_topics', {})),
            json.dumps(deep_context.get('historical_topics', {})),
            json.dumps(deep_context.get('emotional_arc', {})),
            json.dumps(deep_context.get('conversation_rhythm', {})),
            json.dumps(deep_context.get('user_patterns', {})),
            json.dumps(deep_context.get('unfinished_threads', {}))
        ))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ, –µ—Å–ª–∏ –µ—Å—Ç—å
        if memory_reference:
            cursor.execute("""
                INSERT INTO conversation_memory 
                (user_id, memory_type, content, emotional_weight)
                VALUES (?, 'associative', ?, ?)
            """, (user_id, memory_reference, emotional_state.get('intensity', 0.5)))
        
        conn.commit()
        conn.close()
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    user = update.effective_user
    welcome_text = f"""
üëã –ü—Ä–∏–≤–µ—Ç, {user.first_name}!

–Ø –±–æ—Ç —Å –≥–ª—É–±–æ–∫–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º. –Ø –∑–∞–ø–æ–º–∏–Ω–∞—é –Ω–∞—à–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä—ã –∏ —Å—Ç–∞—Ä–∞—é—Å—å –≤–µ—Å—Ç–∏ –±–µ—Å–µ–¥—É –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫.

–ß—Ç–æ —É–º–µ—é:
‚Ä¢ –ó–∞–ø–æ–º–∏–Ω–∞—Ç—å —Ç–µ–º—ã –Ω–∞—à–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤
‚Ä¢ –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–µ—Å–µ–¥—ã
‚Ä¢ –ü—Ä–æ—è–≤–ª—è—Ç—å —ç–º–ø–∞—Ç–∏—é –∏ –ø–æ–Ω–∏–º–∞–Ω–∏–µ
‚Ä¢ –í–µ—Å—Ç–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—É—é —á–µ–ª–æ–≤–µ—á–µ—Å–∫—É—é –±–µ—Å–µ–¥—É

–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –º–Ω–µ —á—Ç–æ-–Ω–∏–±—É–¥—å, –∏ –º—ã –Ω–∞—á–Ω–µ–º –æ–±—â–∞—Ç—å—Å—è!

–¢–∞–∫–∂–µ –¥–æ—Å—Ç—É–ø–Ω—ã –∫–æ–º–∞–Ω–¥—ã:
/context - –ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
/memory - –ø–æ–∫–∞–∑–∞—Ç—å –ø–∞–º—è—Ç—å –æ –±–µ—Å–µ–¥–∞—Ö
"""
    await update.message.reply_text(welcome_text)

async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫"""
    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {context.error}")
    
    if update and update.message:
        try:
            await update.message.reply_text(
                "‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –ø–æ–∑–∂–µ."
            )
        except Exception as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ: {e}")

class UserDatabase:
    def __init__(self, db_name="bot_users.db"):
        self.db_name = db_name
        self.init_database()
    
    def init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Å—Ö–µ–º–æ–π"""
        conn = sqlite3.connect(self.db_name)
        cursor = conn.cursor()
        
        # –¢–∞–±–ª–∏—Ü–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS users (
                user_id INTEGER PRIMARY KEY,
                username TEXT,
                first_name TEXT,
                last_name TEXT,
                gender TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                last_interaction DATETIME,
                conversation_style TEXT DEFAULT 'balanced',
                emotional_profile TEXT
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ —Å–æ–æ–±—â–µ–Ω–∏–π —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –ø–æ–ª—è–º–∏
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS messages (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER,
                message_text TEXT,
                bot_response TEXT,
                message_type TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                emotions TEXT,
                style TEXT,
                typing_time REAL,
                thinking_time REAL,
                context_hash TEXT,
                emotional_score REAL,
                topic_tags TEXT,
                FOREIGN KEY (user_id) REFERENCES users (user_id)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS conversation_context (
                user_id INTEGER PRIMARY KEY,
                current_topics TEXT,
                historical_topics TEXT,
                emotional_arc TEXT,
                conversation_rhythm TEXT,
                user_patterns TEXT,
                unfinished_threads TEXT,
                last_deep_analysis DATETIME,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users (user_id)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –ø–∞–º—è—Ç–∏
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS conversation_memory (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER,
                memory_type TEXT,
                content TEXT,
                emotional_weight REAL,
                last_recalled DATETIME,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users (user_id)
            )
        ''')
        
        conn.commit()
        conn.close()
        logger.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    def get_user(self, user_id: int) -> Optional[tuple]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ ID"""
        try:
            conn = sqlite3.connect(self.db_name)
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM users WHERE user_id = ?", (user_id,))
            user = cursor.fetchone()
            conn.close()
            return user
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
            return None
    
    def create_user(self, user_id: int, username: str = None, 
                   first_name: str = None, last_name: str = None):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            conn = sqlite3.connect(self.db_name)
            cursor = conn.cursor()
            cursor.execute("""
                INSERT INTO users (user_id, username, first_name, last_name)
                VALUES (?, ?, ?, ?)
                ON CONFLICT(user_id) DO UPDATE SET
                username = excluded.username,
                first_name = excluded.first_name,
                last_name = excluded.last_name,
                last_interaction = CURRENT_TIMESTAMP
            """, (user_id, username, first_name, last_name))
            conn.commit()
            conn.close()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
    
    def update_user_interaction(self, user_id: int):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è"""
        try:
            conn = sqlite3.connect(self.db_name)
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE users SET last_interaction = CURRENT_TIMESTAMP 
                WHERE user_id = ?
            """, (user_id,))
            conn.commit()
            conn.close()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
    
    def get_user_stats(self, user_id: int) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            conn = sqlite3.connect(self.db_name)
            cursor = conn.cursor()
            
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π
            cursor.execute("SELECT COUNT(*) FROM messages WHERE user_id = ?", (user_id,))
            message_count = cursor.fetchone()[0]
            
            # –ü–æ—Å–ª–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            cursor.execute("SELECT last_interaction FROM users WHERE user_id = ?", (user_id,))
            last_interaction = cursor.fetchone()[0]
            
            # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–µ–º—ã
            cursor.execute("""
                SELECT topic_tags, COUNT(*) as count 
                FROM messages 
                WHERE user_id = ? AND topic_tags IS NOT NULL
                GROUP BY topic_tags 
                ORDER BY count DESC 
                LIMIT 5
            """, (user_id,))
            popular_topics = cursor.fetchall()
            
            conn.close()
            
            return {
                'message_count': message_count,
                'last_interaction': last_interaction,
                'popular_topics': popular_topics
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
            return {}

async def process_message_with_deep_context(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –≥–ª—É–±–æ–∫–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º"""
    try:
        user_id = update.effective_user.id
        user_message = update.message.text
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        user_context = get_user_context(user_id)
        history = user_context.get('history', [])
        
        # –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        deep_context = context_analyzer.extract_deep_context(user_message, history, user_context)
        
        # –ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        emotional_state = emotional_intelligence.analyze_emotional_state(user_message, history)
        
        # –ü–æ–∏—Å–∫ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π
        memory_reference = memory_system.create_contextual_memory(user_message, history, user_context)
        
        # –°–∏–º—É–ª—è—Ü–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        response_metrics = await conversation_simulator.simulate_human_response(
            user_message, user_context, history
        )
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ —Å –≥–ª—É–±–æ–∫–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        prompt = create_deep_context_prompt(user_message, deep_context, emotional_state, memory_reference, user_context)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        bot_response = await generate_ai_response(prompt, response_metrics['conversation_style'])
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —ç–º–ø–∞—Ç–∏–∏ –∏ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        bot_response = emotional_intelligence.generate_empathic_response(emotional_state, bot_response)
        if memory_reference and random.random() < 0.6:
            bot_response = f"{memory_reference} {bot_response}"
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        save_complete_context(user_id, user_message, bot_response, deep_context, 
                            emotional_state, response_metrics, memory_reference)
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞
        await update.message.reply_text(bot_response)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        await update.message.reply_text("–ß—Ç–æ-—Ç–æ —è –∑–∞–ø—É—Ç–∞–ª–∞—Å—å... –î–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â–µ —Ä–∞–∑?")

def create_deep_context_prompt(message, deep_context, emotional_state, memory_reference, user_context):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ —Å –≥–ª—É–±–æ–∫–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
    prompt = f"""
–¢—ã - –æ–ø—ã—Ç–Ω—ã–π —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –≤–µ–¥–µ—Ç –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—É—é —á–µ–ª–æ–≤–µ—á–µ—Å–∫—É—é –±–µ—Å–µ–¥—É.

–¢–ï–ö–£–©–ò–ô –ö–û–ù–¢–ï–ö–°–¢:
- –°–æ–æ–±—â–µ–Ω–∏–µ: {message}
- –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: {emotional_state['dominant_emotion']} (–∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å: {emotional_state['intensity']:.2f})
- –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {emotional_state['emotional_trend']}
- –¢–µ–º–ø –±–µ—Å–µ–¥—ã: {deep_context['conversation_rhythm']['pace']}

–ò–°–¢–û–†–ò–Ø –ë–ï–°–ï–î–´:
–¢–µ–∫—É—â–∏–µ —Ç–µ–º—ã: {', '.join(list(deep_context['current_topics'].keys())[:3])}
–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ç–µ–º—ã: {', '.join(list(deep_context['historical_topics'].keys())[:3])}
–ù–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã: {len(deep_context['unfinished_threads']['user_questions'])}

–ü–ê–¢–¢–ï–†–ù–´ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
–°—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–æ–≤: {deep_context['user_patterns']['response_style']}
–ß–∞—Å—Ç–æ—Ç–∞ –≤–æ–ø—Ä–æ—Å–æ–≤: {deep_context['user_patterns']['question_frequency']:.2f}

{'–í–û–°–ü–û–ú–ò–ù–ê–ù–ò–ï: ' + memory_reference if memory_reference else ''}

–í–ï–î–ò –°–ï–ë–Ø –ö–ê–ö –ñ–ò–í–û–ô –ß–ï–õ–û–í–ï–ö:
- –£—á–∏—Ç—ã–≤–∞–π –≤–µ—Å—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–µ—Å–µ–¥—ã
- –ü—Ä–æ—è–≤–ª—è–π —ç–º–ø–∞—Ç–∏—é –∫ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é
- –ò—Å–ø–æ–ª—å–∑—É–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ—á–µ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π –ª–æ–≥–∏—á–µ—Å–∫—É—é —Å–≤—è–∑–Ω–æ—Å—Ç—å
- –ë—É–¥—å –≤–Ω–∏–º–∞—Ç–µ–ª–µ–Ω –∫ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–º —Ç–µ–º–∞–º

–¢–≤–æ–π –æ—Ç–≤–µ—Ç (–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π, —á–µ–ª–æ–≤–µ—á–Ω—ã–π, –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ-–æ—Å–æ–∑–Ω–∞–Ω–Ω—ã–π):
"""
    return prompt

async def generate_ai_response(prompt, style):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å —É—á–µ—Ç–æ–º —Å—Ç–∏–ª—è"""
    temperature_map = {
        'active': 0.8,
        'reactive': 0.6,
        'balanced': 0.7,
        'deep': 0.75
    }
    
    temperature = temperature_map.get(style, 0.7)
    
    # –ó–∞–ø—Ä–æ—Å –∫ Yandex GPT
    headers = {
        "Authorization": f"Api-Key {YANDEX_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "modelUri": f"gpt://{YANDEX_FOLDER_ID}/yandexgpt-lite",
        "completionOptions": {
            "stream": False,
            "temperature": temperature,
            "maxTokens": 2000
        },
        "messages": [
            {
                "role": "system",
                "text": "–¢—ã –æ–ø—ã—Ç–Ω—ã–π —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫, –≤–µ–¥—É—â–∏–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—É—é —á–µ–ª–æ–≤–µ—á–µ—Å–∫—É—é –±–µ—Å–µ–¥—É."
            },
            {
                "role": "user",
                "text": prompt
            }
        ]
    }
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(YANDEX_API_URL, headers=headers, json=payload) as response:
                if response.status == 200:
                    data = await response.json()
                    return data['result']['alternatives'][0]['message']['text']
                else:
                    return "–î–∞–≤–∞–π –ø–æ–≥–æ–≤–æ—Ä–∏–º –æ —á–µ–º-—Ç–æ –¥—Ä—É–≥–æ–º? –ß—Ç–æ —Ç–µ–±—è –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç?"
                    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ Yandex GPT: {e}")
        return "–ò–∑–≤–∏–Ω–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª–∞—Å—å... –ú–æ–∂–µ—à—å –ø–æ–≤—Ç–æ—Ä–∏—Ç—å?"

async def context_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç"""
    user_id = update.effective_user.id
    user_context = get_user_context(user_id)
    
    response = "üìä –¢–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–µ—Å–µ–¥—ã:\n\n"
    
    if 'deep_context' in user_context:
        dc = user_context['deep_context']
        response += f"üéØ –¢–µ–º—ã: {', '.join(list(dc.get('current_topics', {}).keys())[:3])}\n"
        response += f"üìà –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {dc.get('emotional_arc', {}).get('current_mood', 0.5):.2f}\n"
        response += f"üèÉ –¢–µ–º–ø: {dc.get('conversation_rhythm', {}).get('pace', 'medium')}\n"
        response += f"üí≠ –í–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π: {len(dc.get('historical_topics', {}))}\n"
    
    await update.message.reply_text(response)

async def memory_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑–∞—Ç—å –ø–∞–º—è—Ç—å –æ –±–µ—Å–µ–¥–µ"""
    user_id = update.effective_user.id
    user_context = get_user_context(user_id)
    
    response = "üß† –ü–∞–º—è—Ç—å –æ –Ω–∞—à–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–∞—Ö:\n\n"
    
    if 'deep_context' in user_context:
        dc = user_context['deep_context']
        historical = list(dc.get('historical_topics', {}).keys())
        if historical:
            response += "–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ç–µ–º—ã:\n"
            for topic in historical[:5]:
                response += f"‚Ä¢ {topic}\n"
        else:
            response += "–ï—â–µ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ç–µ–º"
    
    await update.message.reply_text(response)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤
    if not TELEGRAM_BOT_TOKEN:
        logger.error("‚ùå TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    UserDatabase()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("context", context_command))
    application.add_handler(CommandHandler("memory", memory_command))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, process_message_with_deep_context))
    application.add_error_handler(error_handler)
    
    logger.info("ü§ñ –ë–æ—Ç —Å –≥–ª—É–±–æ–∫–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    
    # –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    main()
