import sqlite3
import json
from datetime import datetime
import os
import logging
import requests
import asyncio
import time
import re
import random
import signal
import sys
import aiohttp
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
from datetime import datetime, timedelta
from telegram import Update
from telegram.ext import Application, MessageHandler, filters, ContextTypes, CommandHandler, CallbackContext
from telegram.error import Conflict
from enum import Enum
from collections import deque, defaultdict
import numpy as np
import humanize
from dateutil import parser
import uuid
from typing import Dict, Any, List, Optional
import hashlib
import json

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è graceful shutdown
def signal_handler(sig, frame):
    print("\nüõë –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –±–æ—Ç–∞...")
    if 'application' in globals() and application.running:
        application.stop()
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# –í–∞—à–∏ –∫–ª—é—á–∏
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
YANDEX_API_KEY = os.getenv("YANDEX_API_KEY")
YANDEX_FOLDER_ID = os.getenv("YANDEX_FOLDER_ID")

# URL API Yandex GPT
YANDEX_API_URL = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"

# –ö–æ–Ω—Ç–µ–∫—Å—Ç –±–µ—Å–µ–¥—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
conversation_context = {}

class PersonalityGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –∏ –ª–∏—á–Ω–æ—Å—Ç–∏ –±–æ—Ç–∞"""
    
    def __init__(self):
        self.personas = self._create_personas()
        self.interests = self._create_interests()
        self.backstories = self._create_backstories()
        
    def _create_personas(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π"""
        return {
            'friendly_creative': {
                'name': ['–°–∞—à–∞', '–õ–µ–Ω–∞', '–ú–∞–∫—Å', '–ê–Ω—è', '–î–∏–º–∞', '–ö–∞—Ç—è'],
                'traits': ['–¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π', '—Ç–≤–æ—Ä—á–µ—Å–∫–∏–π', '–ª—é–±–æ–∑–Ω–∞—Ç–µ–ª—å–Ω—ã–π', '—ç–º–ø–∞—Ç–∏—á–Ω—ã–π'],
                'speech_style': '–Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π, —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —ç–º–æ–¥–∑–∏',
                'question_rate': 0.4
            },
            'thoughtful_analyst': {
                'name': ['–ê–ª–µ–∫—Å–µ–π', '–ú–∞—Ä–∏—è', '–î–º–∏—Ç—Ä–∏–π', '–ï–ª–µ–Ω–∞', '–°–µ—Ä–≥–µ–π'],
                'traits': ['–∞–Ω–∞–ª–∏—Ç–∏—á–Ω—ã–π', '–≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã–π', '–ª–æ–≥–∏—á–Ω—ã–π', '–æ—Å–Ω–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π'],
                'speech_style': '–±–æ–ª–µ–µ —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π',
                'question_rate': 0.3
            },
            'energetic_enthusiast': {
                'name': ['–í–∞–Ω—è', '–û–ª—è', '–ê—Ä—Ç—ë–º', '–Æ–ª—è', '–ö–∏—Ä–∏–ª–ª'],
                'traits': ['—ç–Ω–µ—Ä–≥–∏—á–Ω—ã–π', '–æ–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω—ã–π', '—Å–ø–æ–Ω—Ç–∞–Ω–Ω—ã–π', '–≤–æ—Å—Ç–æ—Ä–∂–µ–Ω–Ω—ã–π'],
                'speech_style': '—ç–∫—Å–ø—Ä–µ—Å—Å–∏–≤–Ω—ã–π, —Å –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏—è–º–∏',
                'question_rate': 0.5
            }
        }
    
    def _create_interests(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –∏ —Ö–æ–±–±–∏"""
        return {
            'creative': ['—Ä–∏—Å–æ–≤–∞–Ω–∏–µ', '—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è', '–ø–∏—Å—å–º–æ', '–º—É–∑—ã–∫–∞', '–∫—É–ª–∏–Ω–∞—Ä–∏—è'],
            'intellectual': ['—á—Ç–µ–Ω–∏–µ', '–Ω–∞—É–∫–∞', '–∏—Å—Ç–æ—Ä–∏—è', '—Ñ–∏–ª–æ—Å–æ—Ñ–∏—è', '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏'],
            'active': ['—Å–ø–æ—Ä—Ç', '–ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è', '—Ç–∞–Ω—Ü—ã', '–π–æ–≥–∞', '–≤–µ–ª–æ—Å–ø–æ—Ä—Ç'],
            'social': ['–≤—Å—Ç—Ä–µ—á–∏ —Å –¥—Ä—É–∑—å—è–º–∏', '–≤–æ–ª–æ–Ω—Ç–µ—Ä—Å—Ç–≤–æ', '–º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è', '–∫–ª—É–±—ã –ø–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º']
        }
    
    def _create_backstories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥—ã—Å—Ç–æ—Ä–∏–π"""
        return [
            "–ù–µ–¥–∞–≤–Ω–æ –ø–µ—Ä–µ–µ—Ö–∞–ª –≤ –Ω–æ–≤—ã–π –≥–æ—Ä–æ–¥ –∏ –∏–∑—É—á–∞—é –º–µ—Å—Ç–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏",
            "–†–∞–±–æ—Ç–∞—é –≤ —Ç–≤–æ—Ä—á–µ—Å–∫–æ–π —Å—Ñ–µ—Ä–µ –∏ –ª—é–±–ª—é –¥–µ–ª–∏—Ç—å—Å—è –∏–¥–µ—è–º–∏",
            "–£—á—É—Å—å –≤ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–µ –∏ –∞–∫—Ç–∏–≤–Ω–æ –ø–æ–∑–Ω–∞—é –º–∏—Ä –≤–æ–∫—Ä—É–≥",
            "–ó–∞–Ω–∏–º–∞—é—Å—å —É–¥–∞–ª–µ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç–æ–π –∏ —Ü–µ–Ω—é –∂–∏–≤–æ–µ –æ–±—â–µ–Ω–∏–µ",
            "–ü—É—Ç–µ—à–µ—Å—Ç–≤—É—é –∏ —Å–æ–±–∏—Ä–∞—é –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–∏ –ª—é–¥–µ–π"
        ]
    
    def generate_personality(self, user_gender_hint=None):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω–æ–π –ª–∏—á–Ω–æ—Å—Ç–∏"""
        persona_type = random.choice(list(self.personas.keys()))
        persona = self.personas[persona_type]
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ —Å–ª—É—á–∞–π–Ω–æ
        if user_gender_hint:
            gender = user_gender_hint
        else:
            gender = random.choice(['male', 'female'])
        
        # –í—ã–±–æ—Ä –∏–º–µ–Ω–∏ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø–æ–ª–æ–º
        if gender == 'male':
            name = random.choice([n for n in persona['name'] if not n.endswith(('–∞', '—è'))])
        else:
            name = random.choice([n for n in persona['name'] if n.endswith(('–∞', '—è'))])
        
        # –í—ã–±–æ—Ä –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤
        interest_categories = random.sample(list(self.interests.keys()), 2)
        interests = []
        for category in interest_categories:
            interests.extend(random.sample(self.interests[category], 2))
        
        personality = {
            'name': name,
            'gender': gender,
            'persona_type': persona_type,
            'traits': persona['traits'],
            'speech_style': persona['speech_style'],
            'interests': interests[:3],
            'backstory': random.choice(self.backstories),
            'question_rate': persona['question_rate'],
            'created_at': datetime.now()
        }
        
        return personality
    
    def get_gender_pronouns(self, gender):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏–π –ø–æ –ø–æ–ª—É"""
        if gender == 'male':
            return {
                'subject': '–æ–Ω',
                'object': '–µ–≥–æ',
                'possessive': '–µ–≥–æ',
                'reflexive': '—Å–µ–±—è',
                'self': '—è',
                'my': '–º–æ–π',
                'me': '–º–Ω–µ'
            }
        else:
            return {
                'subject': '–æ–Ω–∞',
                'object': '–µ—ë',
                'possessive': '–µ—ë',
                'reflexive': '—Å–µ–±—è',
                'self': '—è',
                'my': '–º–æ—è',
                'me': '–º–Ω–µ'
            }

class DeepContextAnalyzer:
    """–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –±–µ—Å–µ–¥—ã"""
    
    def __init__(self):
        self.topic_memory = defaultdict(lambda: {'count': 0, 'last_mentioned': None, 'sentiment': 0.5})
        self.conversation_flow = deque(maxlen=10)
        
    def extract_deep_context(self, message, history, user_context):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–ª—É–±–æ–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –≤—Å–µ–π –±–µ—Å–µ–¥—ã"""
        context = {
            'current_topics': self._extract_topics(message),
            'historical_topics': self._analyze_historical_topics(history),
            'emotional_arc': self._analyze_emotional_arc(history),
            'conversation_rhythm': self._analyze_conversation_rhythm(history),
            'unfinished_threads': self._find_unfinished_threads(history),
            'user_patterns': self._analyze_user_patterns(history, user_context)
        }
        return context
    
    def _extract_topics(self, text):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º —Å –≤–µ—Å–∞–º–∏"""
        words = re.findall(r'\b[–∞-—è—ë]{3,}\b', text.lower())
        stop_words = {'—ç—Ç–æ—Ç', '–æ—á–µ–Ω—å', '–∫–æ—Ç–æ—Ä—ã–π', '–∫–æ–≥–¥–∞', '–ø–æ—Ç–æ–º', '—Ç–æ–≥–¥–∞', '–≤–æ–æ–±—â–µ', '–∑–Ω–∞—á–∏—Ç'}
        topics = {}
        
        for word in set(words) - stop_words:
            if len(word) > 2:
                weight = words.count(word) * 0.3
                if word in text[:50]:
                    weight += 0.2
                topics[word] = min(1.0, weight)
        
        return dict(sorted(topics.items(), key=lambda x: x[1], reverse=True)[:5])
    
    def _analyze_historical_topics(self, history):
        """–ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Ç–µ–º"""
        historical_topics = {}
        for i, msg in enumerate(history[-20:]):
            if 'user' in msg:
                topics = self._extract_topics(msg['user'])
                for topic, weight in topics.items():
                    if topic in historical_topics:
                        historical_topics[topic] += weight * (0.9 ** i)
                    else:
                        historical_topics[topic] = weight * (0.9 ** i)
        
        return dict(sorted(historical_topics.items(), key=lambda x: x[1], reverse=True)[:8])
    
    def _analyze_emotional_arc(self, history):
        """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –¥—É–≥–∏ –±–µ—Å–µ–¥—ã"""
        emotions = []
        for msg in history[-10:]:
            if 'user' in msg:
                emotional_score = self._calculate_emotional_score(msg['user'])
                emotions.append(emotional_score)
        
        if len(emotions) > 2:
            trend = np.polyfit(range(len(emotions)), emotions, 1)[0]
            return {
                'current_mood': emotions[-1] if emotions else 0.5,
                'trend': trend,
                'volatility': np.std(emotions) if len(emotions) > 1 else 0
            }
        return {'current_mood': 0.5, 'trend': 0, 'volatility': 0}
    
    def _calculate_emotional_score(self, text):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–∫–æ—Ä–∞"""
        positive = sum(1 for word in ['—Ä–∞–¥', '—Å—á–∞—Å—Ç–ª–∏–≤', '—Ö–æ—Ä–æ—à–æ', '–æ—Ç–ª–∏—á–Ω–æ', '–ª—é–±–ª—é'] if word in text.lower())
        negative = sum(1 for word in ['–≥—Ä—É—Å—Ç–Ω–æ', '–ø–ª–æ—Ö–æ', '–Ω–µ–Ω–∞–≤–∏–∂—É', '–∑–ª–æ–π', '–æ–±–∏–¥–Ω–æ'] if word in text.lower())
        
        total = positive + negative
        if total == 0:
            return 0.5
        return positive / total
    
    def _analyze_conversation_rhythm(self, history):
        """–ê–Ω–∞–ª–∏–∑ —Ä–∏—Ç–º–∞ –±–µ—Å–µ–¥—ã"""
        if len(history) < 3:
            return {'pace': 'medium', 'initiative': 0.5}
        
        response_times = []
        for i in range(1, min(10, len(history))):
            if 'timestamp' in history[i] and 'timestamp' in history[i-1]:
                delta = (history[i]['timestamp'] - history[i-1]['timestamp']).total_seconds()
                response_times.append(delta)
        
        avg_response = np.mean(response_times) if response_times else 60
        if avg_response < 30:
            pace = 'fast'
        elif avg_response < 120:
            pace = 'medium'
        else:
            pace = 'slow'
        
        user_messages = sum(1 for msg in history[-10:] if 'user' in msg)
        initiative = user_messages / min(10, len(history))
        
        return {'pace': pace, 'initiative': initiative}
    
    def _find_unfinished_threads(self, history):
        """–ü–æ–∏—Å–∫ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö —Ç–µ–º"""
        unfinished = []
        questions = []
        
        for msg in history[-10:]:
            if 'user' in msg and '?' in msg['user']:
                questions.append(msg['user'])
            if 'bot' in msg and '?' in msg['bot']:
                next_msgs = history[history.index(msg)+1:]
                if not any('user' in m and '?' not in m.get('user', '') for m in next_msgs[:2]):
                    unfinished.append(msg['bot'])
        
        return {'user_questions': questions[-3:], 'bot_questions': unfinished}
    
    def _analyze_user_patterns(self, history, user_context):
        """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        patterns = {
            'question_frequency': 0,
            'emotional_consistency': 0,
            'topic_persistence': 0,
            'response_style': 'balanced'
        }
        
        if len(history) < 5:
            return patterns
        
        questions = sum(1 for msg in history[-10:] if 'user' in msg and '?' in msg['user'])
        patterns['question_frequency'] = questions / min(10, len(history))
        
        message_lengths = [len(msg.get('user', '')) for msg in history[-10:] if 'user' in msg]
        if message_lengths:
            avg_length = np.mean(message_lengths)
            patterns['response_style'] = 'detailed' if avg_length > 50 else 'concise'
        
        return patterns

class HumanConversationSimulator:
    """–°–∏–º—É–ª—è—Ç–æ—Ä —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π –±–µ—Å–µ–¥—ã"""
    
    def __init__(self):
        self.typing_profiles = self._create_typing_profiles()
        self.conversation_styles = self._create_conversation_styles()
        self.memory_system = MemorySystem()
        
    def _create_typing_profiles(self):
        """–ü—Ä–æ—Ñ–∏–ª–∏ –ø–µ—á–∞—Ç–∞–Ω–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ª–∏—á–Ω–æ—Å—Ç–∏"""
        return {
            'fast': {'base_speed': 0.02, 'variation': 0.7, 'error_rate': 0.005},
            'normal': {'base_speed': 0.03, 'variation': 0.8, 'error_rate': 0.01},
            'thoughtful': {'base_speed': 0.04, 'variation': 0.9, 'error_rate': 0.015},
            'emotional': {'base_speed': 0.025, 'variation': 1.2, 'error_rate': 0.02}
        }
    
    def _create_conversation_styles(self):
        """–°—Ç–∏–ª–∏ –≤–µ–¥–µ–Ω–∏—è –±–µ—Å–µ–¥—ã"""
        return {
            'active': {'question_rate': 0.4, 'topic_change': 0.3, 'detail_level': 0.8},
            'reactive': {'question_rate': 0.2, 'topic_change': 0.1, 'detail_level': 0.6},
            'balanced': {'question_rate': 0.3, 'topic_change': 0.2, 'detail_level': 0.7},
            'deep': {'question_rate': 0.25, 'topic_change': 0.15, 'detail_level': 0.9}
        }
    
    def _select_conversation_style(self, deep_context):
        """–í—ã–±–æ—Ä —Å—Ç–∏–ª—è –±–µ—Å–µ–¥—ã based on –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        if not deep_context or 'emotional_arc' not in deep_context:
            return 'balanced'
        
        emotional_arc = deep_context.get('emotional_arc', {}) or {}
        conversation_rhythm = deep_context.get('conversation_rhythm', {}) or {}
        user_patterns = deep_context.get('user_patterns', {}) or {}
        
        mood = emotional_arc.get('current_mood', 0.5)
        pace = conversation_rhythm.get('pace', 'medium')
        
        if mood > 0.7 and pace == 'fast':
            return 'active'
        elif mood < 0.3:
            return 'reactive'
        elif user_patterns.get('response_style') == 'detailed':
            return 'deep'
        else:
            return 'balanced'
    
    def _select_typing_profile(self, deep_context):
        """–í—ã–±–æ—Ä –ø—Ä–æ—Ñ–∏–ª—è –ø–µ—á–∞—Ç–∞–Ω–∏—è"""
        emotional_arc = deep_context.get('emotional_arc', {}) or {}
        conversation_rhythm = deep_context.get('conversation_rhythm', {}) or {}
        
        volatility = emotional_arc.get('volatility', 0.1)
        pace = conversation_rhythm.get('pace', 'medium')
        
        if volatility > 0.3:
            return 'emotional'
        elif pace == 'fast':
            return 'fast'
        else:
            return random.choice(['normal', 'thoughtful'])
    
    def _calculate_thinking_time(self, message, deep_context, history):
        """–í—Ä–µ–º—è –Ω–∞ –æ–±–¥—É–º—ã–≤–∞–Ω–∏–µ"""
        try:
            base_time = float(random.uniform(0.5, 2.0))
            
            emotional_arc = deep_context.get('emotional_arc', {}) or {}
            
            complexity = 1.0
            if '?' in message:
                complexity += 0.5
            if len(message) > 100:
                complexity += 0.3
            
            volatility = float(emotional_arc.get('volatility', 0.1))
            if volatility > 0.2:
                complexity += 0.4
            
            if len(history) > 5:
                recent_emotional = [m for m in history[-3:] if 'emotional_score' in m]
                if recent_emotional and any(float(m.get('emotional_score', 0.5)) < 0.3 for m in recent_emotional):
                    complexity += 0.5
            
            return float(base_time) * float(complexity)
            
        except (TypeError, ValueError) as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –æ–±–¥—É–º—ã–≤–∞–Ω–∏—è: {e}")
            return 1.0
    
    def _calculate_typing_time(self, message, profile, context):
        """–í—Ä–µ–º—è –ø–µ—á–∞—Ç–∞–Ω–∏—è"""
        try:
            profile_config = self.typing_profiles.get(profile, self.typing_profiles['normal'])
            
            base_speed = float(profile_config.get('base_speed', 0.03))
            variation_range = float(profile_config.get('variation', 0.8))
            
            base_time = len(message) * base_speed
            
            variation = random.uniform(1 - variation_range, 1 + variation_range)
            
            messages_count = int(context.get('messages_count', 0))
            experience = max(0.7, 1.0 - (messages_count * 0.0005))
            
            return float(base_time) * float(variation) * float(experience)
            
        except (TypeError, ValueError) as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –ø–µ—á–∞—Ç–∞–Ω–∏—è: {e}")
            return len(message) * 0.03
    
    async def simulate_human_response(self, message, context, history):
        """–°–∏–º—É–ª—è—Ü–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
        try:
            deep_context = context.get('deep_context', {}) or {}
            
            conversation_style = self._select_conversation_style(deep_context)
            typing_profile = self._select_typing_profile(deep_context)
            
            thinking_time = self._calculate_thinking_time(message, deep_context, history)
            if thinking_time > 0.5:
                await asyncio.sleep(min(thinking_time, 5.0))
            
            typing_time = self._calculate_typing_time(message, typing_profile, context)
            await asyncio.sleep(min(typing_time, 3.0))
            
            return {
                'thinking_time': thinking_time,
                'typing_time': typing_time,
                'conversation_style': conversation_style,
                'typing_profile': typing_profile
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–∏–º—É–ª—è—Ü–∏–∏ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")
            return {
                'thinking_time': 1.0,
                'typing_time': len(message) * 0.03,
                'conversation_style': 'balanced',
                'typing_profile': 'normal'
            }

class MemorySystem:
    """–°–∏—Å—Ç–µ–º–∞ –ø–∞–º—è—Ç–∏ –∏ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
    
    def __init__(self):
        self.long_term_memory = {}
        self.associative_triggers = self._create_associative_triggers()
    
    def _create_associative_triggers(self):
        """–ê—Å—Å–æ—Ü–∏–∞—Ç–∏–≤–Ω—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã –¥–ª—è –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
        return {
            'time_based': {
                'today': "–ö—Å—Ç–∞—Ç–∏, –ø–æ–º–Ω–∏—à—å —Å–µ–≥–æ–¥–Ω—è –º—ã –≥–æ–≤–æ—Ä–∏–ª–∏ –æ {}?",
                'recent': "–í—Å–ø–æ–º–Ω–∏–ª –Ω–∞—à –Ω–µ–¥–∞–≤–Ω–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä –ø—Ä–æ {}",
                'past': "–û, –¥–∞–≤–Ω–æ –º—ã –Ω–µ –≤—Å–ø–æ–º–∏–Ω–∞–ª–∏ –æ {}"
            },
            'topic_based': {
                'strong': "–ì–æ–≤–æ—Ä—è –æ {}, –Ω–µ –º–æ–≥—É –Ω–µ –≤—Å–ø–æ–º–Ω–∏—Ç—å...",
                'medium': "–≠—Ç–æ –Ω–∞–ø–æ–º–∏–Ω–∞–µ—Ç –º–Ω–µ –æ {}",
                'weak': "–ö—Å—Ç–∞—Ç–∏, –æ {}..."
            },
            'emotional': {
                'positive': "–í—Å–ø–æ–º–Ω–∏–ª–æ—Å—å –∫–∞–∫ –º—ã –≤–µ—Å–µ–ª–æ –æ–±—Å—É–∂–¥–∞–ª–∏ {}",
                'negative': "–ü–æ–º–Ω–∏—à—å —Ç–æ—Ç —Å–ª–æ–∂–Ω—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä –æ {}?",
                'neutral': "–ü—Ä–∏—à–ª–æ –Ω–∞ —É–º –Ω–∞—à–µ –æ–±—Å—É–∂–¥–µ–Ω–∏–µ {}"
            }
        }
    
    def create_contextual_memory(self, current_message, history, user_context):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
        if len(history) < 3:
            return None
        
        current_topics = set(DeepContextAnalyzer()._extract_topics(current_message).keys())
        memory_candidates = []
        
        for i, past_msg in enumerate(history[-20:]):
            if 'user' in past_msg:
                past_topics = set(DeepContextAnalyzer()._extract_topics(past_msg['user']).keys())
                common_topics = current_topics.intersection(past_topics)
                
                if common_topics:
                    days_ago = (datetime.now() - past_msg.get('timestamp', datetime.now())).days
                    memory_candidates.append({
                        'topics': common_topics,
                        'recency': days_ago,
                        'message': past_msg['user'],
                        'index': i
                    })
        
        if not memory_candidates:
            return None
        
        best_memory = max(memory_candidates, key=lambda x: (
            len(x['topics']) * 0.5 + 
            (1 / (x['recency'] + 1)) * 0.3 +
            random.random() * 0.2
        ))
        
        topic = random.choice(list(best_memory['topics']))
        return self._format_memory_reference(topic, best_memory['recency'])
    
    def _format_memory_reference(self, topic, days_ago):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ"""
        if days_ago == 0:
            time_key = 'today'
        elif days_ago <= 3:
            time_key = 'recent'
        else:
            time_key = 'past'
        
        memory_type = random.choice(['time_based', 'topic_based', 'emotional'])
        intensity = random.choice(['strong', 'medium', 'weak'])
        
        template = self.associative_triggers[memory_type].get(
            intensity, 
            self.associative_triggers[memory_type]['medium']
        )
        
        return template.format(topic)

class EmotionalIntelligence:
    """–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"""
    
    def __init__(self):
        self.empathy_responses = self._create_empathy_responses()
    
    def _create_empathy_responses(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–ø–∞—Ç–∏—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤"""
        return {
            'joy': ['–Ø —Ä–∞–¥ –∑–∞ —Ç–µ–±—è!', '–≠—Ç–æ –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ!', '–ö–∞–∫ –∑–¥–æ—Ä–æ–≤–æ!'],
            'sadness': ['–ü–æ–Ω–∏–º–∞—é —Ç–µ–±—è...', '–ú–Ω–µ –∂–∞–ª—å...', '–î–µ—Ä–∂–∏—Å—å!'],
            'anger': ['–ü–æ–Ω–∏–º–∞—é —Ç–≤–æ–∏ —á—É–≤—Å—Ç–≤–∞', '–≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –Ω–µ–ø—Ä–∏—è—Ç–Ω–æ'],
            'excitement': ['–ó–¥–æ—Ä–æ–≤–æ!', '–í–æ—Å—Ö–∏—Ç–∏—Ç–µ–ª—å–Ω–æ!', '–Ø —Ä–∞–∑–¥–µ–ª—è—é —Ç–≤–æ–π –≤–æ—Å—Ç–æ—Ä–≥!'],
            'confusion': ['–ü–æ–Ω–∏–º–∞—é —Ç–≤–æ—ë –∑–∞–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–æ', '–î–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä–µ–º—Å—è –≤–º–µ—Å—Ç–µ']
        }
       
    def analyze_emotional_state(self, message, history):
        """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
        text = message.lower()
        
        emotions = {
            'joy': self._detect_emotion(text, ['—Ä–∞–¥', '—Å—á–∞—Å—Ç–ª–∏–≤', '—É—Ä–∞', '–∫–ª–∞—Å—Å', '—Å—É–ø–µ—Ä']),
            'sadness': self._detect_emotion(text, ['–≥—Ä—É—Å—Ç–Ω–æ', '–ø–µ—á–∞–ª—å–Ω–æ', '–ø–ª–æ—Ö–æ', '—Ç—è–∂–µ–ª–æ']),
            'anger': self._detect_emotion(text, ['–∑–ª–æ–π', '—Å–µ—Ä–¥–∏—Ç', '–±–µ—Å–∏—Ç', '–Ω–µ–Ω–∞–≤–∏–∂—É']),
            'excitement': self._detect_emotion(text, ['!', '!!', '!!!', '–≤–∞—É', '–æ–≥–æ']),
            'confusion': self._detect_emotion(text, ['?', '??', '???', '–Ω–µ –ø–æ–Ω–∏–º–∞—é', '–∑–∞–ø—É—Ç–∞–ª—Å—è'])
        }
        
        emotional_trend = self._analyze_emotional_trend(history)
        
        return {
            'current_emotions': emotions,
            'dominant_emotion': max(emotions.items(), key=lambda x: x[1])[0],
            'emotional_trend': emotional_trend,
            'intensity': max(emotions.values()) if emotions else 0
        }
    
    def _detect_emotion(self, text, triggers):
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —ç–º–æ—Ü–∏–∏"""
        score = 0
        for trigger in triggers:
            if trigger in text:
                score += 1
        return min(1.0, score * 0.3)
    
    def _analyze_emotional_trend(self, history):
        """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞"""
        if len(history) < 3:
            return 'stable'
        
        recent_scores = []
        for msg in history[-5:]:
            if 'user' in msg:
                score = self._calculate_emotional_score(msg['user'])
                recent_scores.append(score)
        
        if len(recent_scores) > 2:
            trend = np.polyfit(range(len(recent_scores)), recent_scores, 1)[0]
            if abs(trend) > 0.1:
                return 'improving' if trend > 0 else 'worsening'
        return 'stable'
    
    def _calculate_emotional_score(self, text):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–∫–æ—Ä–∞"""
        positive = sum(1 for word in ['—Ä–∞–¥', '—Å—á–∞—Å—Ç–ª–∏–≤', '—Ö–æ—Ä–æ—à–æ', '–æ—Ç–ª–∏—á–Ω–æ'] if word in text.lower())
        negative = sum(1 for word in ['–≥—Ä—É—Å—Ç–Ω–æ', '–ø–ª–æ—Ö–æ', '–Ω–µ–Ω–∞–≤–∏–∂—É', '–∑–ª–æ–π'] if word in text.lower())
        
        total = positive + negative + 0.001
        return positive / total
    
    def generate_empathic_response(self, emotional_state, response):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–ø–∞—Ç–∏—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
        dominant = emotional_state['dominant_emotion']
        intensity = emotional_state['intensity']
        
        if intensity > 0.3:
            emotional_reaction = self._get_emotional_reaction(dominant, intensity)
            if random.random() < 0.6:
                response = f"{emotional_reaction} {response}"
            
            if random.random() < 0.4:
                empathic_phrase = self._get_empathic_phrase(dominant, intensity)
                response = f"{response} {empathic_phrase}"
        
        return response
    
    def _get_emotional_reaction(self, emotion, intensity):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ä–µ–∞–∫—Ü–∏–∏"""
        reactions = {
            'joy': ['üòä', 'üéâ', '‚ú®', 'ü•≥'],
            'sadness': ['üòî', 'ü§ó', '‚ù§Ô∏è', 'üíî'],
            'anger': ['üò†', 'üò§', 'üí¢', '‚ö°'],
            'excitement': ['üòÉ', 'üöÄ', 'üåü', 'üî•'],
            'confusion': ['ü§î', 'üòï', 'üßê', 'üí≠']
        }
        return random.choice(reactions.get(emotion, ['üôÇ']))
    
    def _get_empathic_phrase(self, emotion, intensity):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–ø–∞—Ç–∏—á–Ω–æ–π —Ñ—Ä–∞–∑—ã"""
        phrases = {
            'joy': ['–Ø —Ä–∞–¥ –∑–∞ —Ç–µ–±—è!', '–≠—Ç–æ –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ!', '–ö–∞–∫ –∑–¥–æ—Ä–æ–≤–æ!'],
            'sadness': ['–ü–æ–Ω–∏–º–∞—é —Ç–µ–±—è...', '–ú–Ω–µ –∂–∞–ª—å...', '–î–µ—Ä–∂–∏—Å—å!'],
            'anger': ['–ü–æ–Ω–∏–º–∞—é —Ç–≤–æ–∏ —á—É–≤—Å—Ç–≤–∞', '–≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –Ω–µ–ø—Ä–∏—è—Ç–Ω–æ'],
            'excitement': ['–ó–¥–æ—Ä–æ–≤–æ!', '–í–æ—Å—Ö–∏—Ç–∏—Ç–µ–ª—å–Ω–æ!', '–Ø —Ä–∞–∑–¥–µ–ª—è—é —Ç–≤–æ–π –≤–æ—Å—Ç–æ—Ä–≥!'],
            'confusion': ['–ü–æ–Ω–∏–º–∞—é —Ç–≤–æ—ë –∑–∞–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–æ', '–î–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä–µ–º—Å—è –≤–º–µ—Å—Ç–µ']
        }
        return random.choice(phrases.get(emotion, ['–ü–æ–Ω–∏–º–∞—é...']))

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —ç–∫–∑–µ–º–ø–ª—è—Ä—ã
personality_generator = PersonalityGenerator()
context_analyzer = DeepContextAnalyzer()
conversation_simulator = HumanConversationSimulator()
memory_system = MemorySystem()
emotional_intelligence = EmotionalIntelligence()

def extract_personal_info(message: str) -> Dict[str, str]:
    """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
    info = {}
    
    # –ü–æ–∏—Å–∫ –∏–º–µ–Ω–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏
    name_patterns = [
        r'–º–µ–Ω—è –∑–æ–≤—É—Ç (\w+)', r'—è (\w+)', r'–∑–æ–≤—É—Ç (\w+)', 
        r'–º–æ–µ –∏–º—è (\w+)', r'–∏–º—è (\w+)', r'–∑–≤–∞—Ç—å (\w+)'
    ]
    
    for pattern in name_patterns:
        match = re.search(pattern, message.lower())
        if match:
            name = match.group(1).capitalize()
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∏–º–µ–Ω–∏
            if len(name) > 1 and name.isalpha():
                info['name'] = name
                break
    
    # –ü–æ–∏—Å–∫ –≤–æ–∑—Ä–∞—Å—Ç–∞
    age_patterns = [
        r'–º–Ω–µ (\d+) –ª–µ—Ç', r'–º–Ω–µ (\d+) –≥–æ–¥', r'–≤–æ–∑—Ä–∞—Å—Ç (\d+)', 
        r'(\d+) –ª–µ—Ç', r'(\d+) –≥–æ–¥'
    ]
    
    for pattern in age_patterns:
        match = re.search(pattern, message.lower())
        if match:
            age = match.group(1)
            if age.isdigit() and 1 <= int(age) <= 120:
                info['age'] = age
                break
    
    # –ü–æ–∏—Å–∫ —É–≤–ª–µ—á–µ–Ω–∏–π
    interest_patterns = [
        r'–ª—é–±–ª—é ([^.!?]+)', r'–Ω—Ä–∞–≤–∏—Ç—Å—è ([^.!?]+)', r'—É–≤–ª–µ–∫–∞—é—Å—å ([^.!?]+)',
        r'–∑–∞–Ω–∏–º–∞—é—Å—å ([^.!?]+)', r'—Ö–æ–±–±–∏ ([^.!?]+)', r'–∏–Ω—Ç–µ—Ä–µ—Å—É—é—Å—å ([^.!?]+)'
    ]
    
    for pattern in interest_patterns:
        match = re.search(pattern, message.lower())
        if match:
            interests = match.group(1).strip()
            if len(interests) > 3:
                info['interests'] = interests
                break
    
    return info

def save_user_fact(user_id: int, fact_type: str, fact_value: str, confidence: float = 1.0):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–∫—Ç–∞ —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é"""
    try:
        conn = sqlite3.connect("bot_users.db")
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT OR REPLACE INTO user_facts 
            (user_id, fact_type, fact_value, confidence, last_updated)
            VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)
        """, (user_id, fact_type, fact_value, confidence))
        
        conn.commit()
        conn.close()
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–∫—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")

def get_user_fact(user_id: int, fact_type: str) -> Optional[str]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∞–∫—Ç–∞ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ"""
    try:
        conn = sqlite3.connect("bot_users.db")
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT fact_value, confidence FROM user_facts 
            WHERE user_id = ? AND fact_type = ? 
            ORDER BY confidence DESC, last_updated DESC 
            LIMIT 1
        """, (user_id, fact_type))
        
        result = cursor.fetchone()
        conn.close()
        
        if result and result[1] > 0.5:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            return result[0]
        return None
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∞–∫—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        return None

def handle_personal_questions(message: str, user_context: Dict[str, Any]) -> Optional[str]:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–∏—á–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤"""
    text = message.lower()
    user_id = user_context['user_id']
    
    # –í–æ–ø—Ä–æ—Å—ã –æ –∏–º–µ–Ω–∏ –±–æ—Ç–∞
    name_questions = ['–∫–∞–∫ —Ç–µ–±—è –∑–æ–≤—É—Ç', '—Ç–≤–æ–µ –∏–º—è', '–∫–∞–∫ –∑–æ–≤—É—Ç']
    if any(q in text for q in name_questions):
        bot_personality = user_context.get('bot_personality', {})
        return f"–ú–µ–Ω—è –∑–æ–≤—É—Ç {bot_personality.get('name', '–¥—Ä—É–≥')} üòä"
    
    # –í–æ–ø—Ä–æ—Å—ã –æ –≤–æ–∑—Ä–∞—Å—Ç–µ –±–æ—Ç–∞
    age_questions = ['—Å–∫–æ–ª—å–∫–æ —Ç–µ–±–µ –ª–µ—Ç', '—Ç–≤–æ–π –≤–æ–∑—Ä–∞—Å—Ç', '–∫–∞–∫–æ–π –≤–æ–∑—Ä–∞—Å—Ç']
    if any(q in text for q in age_questions):
        return "–Ø –≤—Å–µ–≥–¥–∞ –º–æ–ª–æ–¥ –¥—É—à–æ–π! –í–æ–∑—Ä–∞—Å—Ç - —ç—Ç–æ –≤—Å–µ–≥–æ –ª–∏—à—å —Ü–∏—Ñ—Ä–∞, –≥–ª–∞–≤–Ω–æ–µ - –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ –æ–±—â–µ–Ω–∏–µ ü§ó"
    
    # –í–æ–ø—Ä–æ—Å—ã –æ –ø–æ–ª–µ –±–æ—Ç–∞
    gender_questions = ['—Ç—ã –ø–∞—Ä–µ–Ω—å', '—Ç—ã –¥–µ–≤—É—à–∫–∞', '—Ç—ã –º—É–∂—á–∏–Ω–∞', '—Ç—ã –∂–µ–Ω—â–∏–Ω–∞', '—Ç—ã –º—É–∂–∏–∫']
    if any(q in text for q in gender_questions):
        return "–Ø –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –±—ã—Ç—å —Ö–æ—Ä–æ—à–∏–º —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–æ–º, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –ø–æ–ª–∞ üòä"
    
    # –í–æ–ø—Ä–æ—Å—ã –æ –∏–º–µ–Ω–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_name_questions = ['–∫–∞–∫ –º–µ–Ω—è –∑–æ–≤—É—Ç', '–º–æ–µ –∏–º—è', '–º–µ–Ω—è –∑–≤–∞—Ç—å']
    if any(q in text for q in user_name_questions):
        user_name = get_user_fact(user_id, 'name')
        if user_name:
            return f"–¢–µ–±—è –∑–æ–≤—É—Ç {user_name}! –ö–∞–∫ –º–æ–∂–Ω–æ –∑–∞–±—ã—Ç—å —Ç–∞–∫–æ–µ –∫—Ä–∞—Å–∏–≤–æ–µ –∏–º—è? üòÑ"
        else:
            return "–¢—ã –µ—â–µ –Ω–µ —Å–∫–∞–∑–∞–ª –º–Ω–µ —Å–≤–æ–µ–≥–æ –∏–º–µ–Ω–∏. –ö–∞–∫ —Ç–µ–±—è –∑–æ–≤—É—Ç? ü§î"
    
    # –í–æ–ø—Ä–æ—Å—ã –æ –≤–æ–∑—Ä–∞—Å—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_age_questions = ['—Å–∫–æ–ª—å–∫–æ –º–Ω–µ –ª–µ—Ç', '–º–æ–π –≤–æ–∑—Ä–∞—Å—Ç']
    if any(q in text for q in user_age_questions):
        user_age = get_user_fact(user_id, 'age')
        if user_age:
            return f"–¢–µ–±–µ {user_age} –ª–µ—Ç! –û—Ç–ª–∏—á–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç –¥–ª—è –Ω–æ–≤—ã—Ö —Å–≤–µ—Ä—à–µ–Ω–∏–π! üåü"
        else:
            return "–¢—ã –µ—â–µ –Ω–µ –≥–æ–≤–æ—Ä–∏–ª –º–Ω–µ –æ —Å–≤–æ–µ–º –≤–æ–∑—Ä–∞—Å—Ç–µ. –°–∫–æ–ª—å–∫–æ —Ç–µ–±–µ –ª–µ—Ç? üòä"
    
    return None

def get_user_context(user_id: int) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    try:
        conn = sqlite3.connect("bot_users.db")
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM users WHERE user_id = ?", (user_id,))
        user_exists = cursor.fetchone()[0] > 0
        
        if not user_exists:
            cursor.execute("""
                INSERT INTO users (user_id, created_at, last_interaction) 
                VALUES (?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
            """, (user_id,))
            conn.commit()
            conn.close()
            return {'user_id': user_id, 'history': [], 'messages_count': 0, 'user_facts': {}}
        
        cursor.execute("SELECT * FROM users WHERE user_id = ?", (user_id,))
        user_data = cursor.fetchone()
        
        cursor.execute("""
            SELECT message_text, bot_response, timestamp, emotional_score, topic_tags 
            FROM messages 
            WHERE user_id = ? 
            ORDER BY timestamp DESC 
            LIMIT 20
        """, (user_id,))
        messages = cursor.fetchall()
        
        cursor.execute("SELECT * FROM conversation_context WHERE user_id = ?", (user_id,))
        context_data = cursor.fetchone()
        
        cursor.execute("SELECT * FROM bot_personality WHERE user_id = ?", (user_id,))
        personality_data = cursor.fetchone()
        
        cursor.execute("SELECT fact_type, fact_value FROM user_facts WHERE user_id = ?", (user_id,))
        user_facts_data = cursor.fetchall()
        
        conn.close()
        
        context = {
            'user_id': user_id,
            'history': [],
            'messages_count': 0,
            'last_interaction': None,
            'user_facts': {}
        }
        
        if user_data:
            context['messages_count'] = user_data[6] if len(user_data) > 6 else 0
            context['last_interaction'] = user_data[5] if len(user_data) > 5 else None
        
        for msg in messages:
            context['history'].append({
                'user': msg[0],
                'bot': msg[1],
                'timestamp': datetime.fromisoformat(msg[2]) if isinstance(msg[2], str) else msg[2],
                'emotional_score': msg[3],
                'topics': json.loads(msg[4]) if msg[4] else []
            })
        
        if context_data:
            try:
                context['deep_context'] = {
                    'current_topics': json.loads(context_data[1]) if context_data[1] else {},
                    'historical_topics': json.loads(context_data[2]) if context_data[2] else {},
                    'emotional_arc': json.loads(context_data[3]) if context_data[3] else {},
                    'conversation_rhythm': json.loads(context_data[4]) if context_data[4] else {},
                    'user_patterns': json.loads(context_data[5]) if context_data[5] else {},
                    'unfinished_threads': json.loads(context_data[6]) if context_data[6] else {}
                }
            except json.JSONDecodeError:
                context['deep_context'] = {}
        
        if personality_data:
            try:
                context['bot_personality'] = json.loads(personality_data[1])
            except json.JSONDecodeError:
                context['bot_personality'] = None
        
        for fact_type, fact_value in user_facts_data:
            context['user_facts'][fact_type] = fact_value
        
        return context
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        return {'user_id': user_id, 'history': [], 'messages_count': 0, 'user_facts': {}}

def save_complete_context(user_id: int, user_message: str, bot_response: str, 
                         deep_context: Dict[str, Any], emotional_state: Dict[str, Any],
                         response_metrics: Dict[str, Any], memory_reference: Optional[str] = None):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –±–µ—Å–µ–¥—ã"""
    try:
        conn = sqlite3.connect("bot_users.db")
        cursor = conn.cursor()
        
        context_hash = hashlib.md5(
            f"{user_id}{user_message}{datetime.now().timestamp()}".encode()
        ).hexdigest()
        
        topics = list(deep_context.get('current_topics', {}).keys())[:5]
        
        cursor.execute("""
            INSERT OR IGNORE INTO users (user_id, created_at, last_interaction) 
            VALUES (?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
        """, (user_id,))
        
        cursor.execute("""
            UPDATE users SET last_interaction = CURRENT_TIMESTAMP WHERE user_id = ?
        """, (user_id,))
        
        cursor.execute("""
            INSERT INTO messages 
            (user_id, message_text, bot_response, message_type, emotions, style, 
             typing_time, thinking_time, context_hash, emotional_score, topic_tags)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            user_id, 
            user_message, 
            bot_response,
            'text',
            json.dumps(emotional_state),
            response_metrics.get('conversation_style', 'balanced'),
            response_metrics.get('typing_time', 0),
            response_metrics.get('thinking_time', 0),
            context_hash,
            emotional_state.get('intensity', 0.5),
            json.dumps(topics)
        ))
        
        cursor.execute("""
            INSERT OR REPLACE INTO conversation_context 
            (user_id, current_topics, historical_topics, emotional_arc, 
             conversation_rhythm, user_patterns, unfinished_threads, last_deep_analysis)
            VALUES (?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
        """, (
            user_id,
            json.dumps(deep_context.get('current_topics', {})),
            json.dumps(deep_context.get('historical_topics', {})),
            json.dumps(deep_context.get('emotional_arc', {})),
            json.dumps(deep_context.get('conversation_rhythm', {})),
            json.dumps(deep_context.get('user_patterns', {})),
            json.dumps(deep_context.get('unfinished_threads', {}))
        ))
        
        if memory_reference:
            cursor.execute("""
                INSERT INTO conversation_memory 
                (user_id, memory_type, content, emotional_weight)
                VALUES (?, 'associative', ?, ?)
            """, (user_id, memory_reference, emotional_state.get('intensity', 0.5)))
        
        conn.commit()
        conn.close()
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")

def save_bot_personality(user_id: int, personality: Dict[str, Any]):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª–∏—á–Ω–æ—Å—Ç–∏ –±–æ—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    try:
        conn = sqlite3.connect("bot_users.db")
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT OR REPLACE INTO bot_personality (user_id, personality_data, created_at)
            VALUES (?, ?, CURRENT_TIMESTAMP)
        """, (user_id, json.dumps(personality)))
        
        conn.commit()
        conn.close()
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–∏—á–Ω–æ—Å—Ç–∏ –±–æ—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")

async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫"""
    error = context.error
    
    if isinstance(error, Conflict):
        logger.error(f"–ö–æ–Ω—Ñ–ª–∏–∫—Ç –±–æ—Ç–∞: {error}")
        return
    
    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {error}")
    
    if update and update.message:
        try:
            await update.message.reply_text(
                "‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –ø–æ–∑–∂–µ."
            )
        except Exception as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ: {e}")

class UserDatabase:
    def __init__(self, db_name="bot_users.db"):
        self.db_name = db_name
        self.init_database()
    
    def init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Å—Ö–µ–º–æ–π"""
        conn = sqlite3.connect(self.db_name)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS users (
                user_id INTEGER PRIMARY KEY,
                username TEXT,
                first_name TEXT,
                last_name TEXT,
                gender TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                last_interaction DATETIME,
                conversation_style TEXT DEFAULT 'balanced',
                emotional_profile TEXT
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS messages (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER,
                message_text TEXT,
                bot_response TEXT,
                message_type TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                emotions TEXT,
                style TEXT,
                typing_time REAL,
                thinking_time REAL,
                context_hash TEXT,
                emotional_score REAL,
                topic_tags TEXT,
                FOREIGN KEY (user_id) REFERENCES users (user_id)
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS conversation_context (
                user_id INTEGER PRIMARY KEY,
                current_topics TEXT,
                historical_topics TEXT,
                emotional_arc TEXT,
                conversation_rhythm TEXT,
                user_patterns TEXT,
                unfinished_threads TEXT,
                last_deep_analysis DATETIME,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users (user_id)
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS conversation_memory (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER,
                memory_type TEXT,
                content TEXT,
                emotional_weight REAL,
                last_recalled DATETIME,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users (user_id)
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS bot_personality (
                user_id INTEGER PRIMARY KEY,
                personality_data TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users (user_id)
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS user_facts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER,
                fact_type TEXT,
                fact_value TEXT,
                confidence REAL DEFAULT 1.0,
                last_updated DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users (user_id),
                UNIQUE(user_id, fact_type)
            )
        ''')
        
        conn.commit()
        conn.close()
        logger.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    def get_user(self, user_id: int) -> Optional[tuple]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ ID"""
        try:
            conn = sqlite3.connect(self.db_name)
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM users WHERE user_id = ?", (user_id,))
            user = cursor.fetchone()
            conn.close()
            return user
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
            return None

async def process_message_with_deep_context(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –≥–ª—É–±–æ–∫–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º"""
    try:
        user_id = update.effective_user.id
        user_message = update.message.text
        
        user_context = get_user_context(user_id)
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏—á–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
        personal_response = handle_personal_questions(user_message, user_context)
        if personal_response:
            await update.message.reply_text(personal_response)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∞–∂–µ –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
            save_complete_context(
                user_id, 
                user_message, 
                personal_response, 
                user_context.get('deep_context', {}), 
                {'dominant_emotion': 'neutral', 'intensity': 0.5, 'emotional_trend': 'stable'}, 
                {'conversation_style': 'balanced', 'typing_time': 0.5, 'thinking_time': 0.5}
            )
            return
        
        history = user_context.get('history', [])
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        personal_info = extract_personal_info(user_message)
        for fact_type, fact_value in personal_info.items():
            save_user_fact(user_id, fact_type, fact_value)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏–ª–∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –ª–∏—á–Ω–æ—Å—Ç–∏ –±–æ—Ç–∞
        if 'bot_personality' not in user_context or not user_context['bot_personality']:
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ –∏–º–µ–Ω–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
            user_name = user_context.get('user_facts', {}).get('name', '')
            gender_hint = None
            if user_name:
                if any(user_name.endswith(end) for end in ['–∞', '—è', '—å—è']):
                    gender_hint = 'female'
                else:
                    gender_hint = 'male'
            
            bot_personality = personality_generator.generate_personality(gender_hint)
            save_bot_personality(user_id, bot_personality)
        else:
            bot_personality = user_context['bot_personality']
        
        # –î–ª—è –Ω–æ–≤—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ä–µ–∂–∏–º
        if len(history) < 3:
            simple_prompt = f"""
–¢—ã - {bot_personality['name']}, {', '.join(bot_personality['traits'][:2])}. 
{bot_personality['backstory']}. –£–≤–ª–µ–∫–∞—é—Å—å {', '.join(bot_personality['interests'][:2])}.

–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ø–∏—Å–∞–ª: "{user_message}". 
–û—Ç–≤–µ—Ç—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –∫—Ä–∞—Ç–∫–æ, –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫ –≤ –Ω–∞—á–∞–ª–µ –±–µ—Å–µ–¥—ã. –ë—É–¥—å –ª–∞–∫–æ–Ω–∏—á–Ω—ã–º (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).
"""
            
            bot_response = await generate_ai_response(simple_prompt, 'balanced')
            
            save_complete_context(
                user_id, 
                user_message, 
                bot_response, 
                {'current_topics': {}, 'historical_topics': {}, 'emotional_arc': {}, 
                 'conversation_rhythm': {}, 'user_patterns': {}, 'unfinished_threads': {}}, 
                {'dominant_emotion': 'neutral', 'intensity': 0.5, 'emotional_trend': 'stable'}, 
                {'conversation_style': 'balanced', 'typing_time': 1.0, 'thinking_time': 1.0}
            )
            
            await update.message.reply_text(bot_response)
            return
        
        # –î–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –∏—Å—Ç–æ—Ä–∏–µ–π - –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        deep_context = context_analyzer.extract_deep_context(user_message, history, user_context)
        emotional_state = emotional_intelligence.analyze_emotional_state(user_message, history)
        memory_reference = memory_system.create_contextual_memory(user_message, history, user_context)
        
        response_metrics = await conversation_simulator.simulate_human_response(
            user_message, user_context, history
        )
        
        prompt = create_deep_context_prompt(user_message, deep_context, emotional_state, 
                                          memory_reference, user_context, bot_personality)
        
        bot_response = await generate_ai_response(prompt, response_metrics['conversation_style'])
        
        bot_response = emotional_intelligence.generate_empathic_response(emotional_state, bot_response)
        if memory_reference and random.random() < 0.6:
            bot_response = f"{memory_reference} {bot_response}"
        
        save_complete_context(user_id, user_message, bot_response, deep_context, 
                            emotional_state, response_metrics, memory_reference)
        
        await update.message.reply_text(bot_response)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        try:
            simple_response = await generate_ai_response(
                f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ø–∏—Å–∞–ª: {user_message}. –û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ.",
                'balanced'
            )
            await update.message.reply_text(simple_response)
        except:
            await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –†–∞—Å—Å–∫–∞–∂–∏, —á—Ç–æ —É —Ç–µ–±—è –Ω–æ–≤–æ–≥–æ?")

def create_deep_context_prompt(message, deep_context, emotional_state, memory_reference, 
                              user_context, bot_personality):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ —Å –≥–ª—É–±–æ–∫–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
    history_length = len(user_context.get('history', []))
    user_facts = user_context.get('user_facts', {})
    user_name = user_facts.get('name', '–¥—Ä—É–≥')
    
    base_prompt = f"""
–¢—ã - {bot_personality['name']}, {random.choice(bot_personality['traits'])} —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫.
{bot_personality['backstory']}. –£–≤–ª–µ–∫–∞—é—Å—å {', '.join(bot_personality['interests'][:2])}.

–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_name}
–°–æ–æ–±—â–µ–Ω–∏–µ: {message}
–≠–º–æ—Ü–∏–∏: {emotional_state.get('dominant_emotion', 'neutral')}
"""

    # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ç–µ–º—ã –µ—Å–ª–∏ –µ—Å—Ç—å
    historical_topics = deep_context.get('historical_topics', {})
    if historical_topics:
        base_prompt += f"\n–†–∞–Ω–µ–µ –æ–±—Å—É–∂–¥–∞–ª–∏: {', '.join(list(historical_topics.keys())[:2])}"
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å
    if memory_reference:
        base_prompt += f"\n{memory_reference}"
    
    base_prompt += f"""
\n–û—Ç–≤–µ—á–∞–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ {bot_personality['name']}.
–ò—Å–ø–æ–ª—å–∑—É–π —Å—Ç–∏–ª—å: {bot_personality['speech_style']}
–ë—É–¥—å {random.choice(bot_personality['traits'])}
\n–¢–≤–æ–π –æ—Ç–≤–µ—Ç:
"""
    
    return base_prompt

async def generate_ai_response(prompt, style):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å —É—á–µ—Ç–æ–º —Å—Ç–∏–ª—è"""
    temperature_map = {
        'active': 0.8,
        'reactive': 0.6,
        'balanced': 0.7,
        'deep': 0.75
    }
    
    temperature = temperature_map.get(style, 0.7)
    
    headers = {
        "Authorization": f"Api-Key {YANDEX_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "modelUri": f"gpt://{YANDEX_FOLDER_ID}/yandexgpt-lite",
        "completionOptions": {
            "stream": False,
            "temperature": temperature,
            "maxTokens": 2000
        },
        "messages": [
            {
                "role": "system",
                "text": "–¢—ã –æ–ø—ã—Ç–Ω—ã–π —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫, –≤–µ–¥—É—â–∏–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—É—é —á–µ–ª–æ–≤–µ—á–µ—Å–∫—É—é –±–µ—Å–µ–¥—É."
            },
            {
                "role": "user",
                "text": prompt
            }
        ]
    }
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(YANDEX_API_URL, headers=headers, json=payload) as response:
                if response.status == 200:
                    data = await response.json()
                    return data['result']['alternatives'][0]['message']['text']
                else:
                    return "–î–∞–≤–∞–π –ø–æ–≥–æ–≤–æ—Ä–∏–º –æ —á–µ–º-—Ç–æ –¥—Ä—É–≥–æ–º? –ß—Ç–æ —Ç–µ–±—è –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç?"
                    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ Yandex GPT: {e}")
        return "–ò–∑–≤–∏–Ω–∏, —è –Ω–µ–º–Ω–æ–≥–æ –∑–∞–ø—É—Ç–∞–ª–∞—Å—å... –ú–æ–∂–µ—à—å –ø–æ–≤—Ç–æ—Ä–∏—Ç—å?"

async def context_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç"""
    user_id = update.effective_user.id
    user_context = get_user_context(user_id)
    
    response = "üìä –¢–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–µ—Å–µ–¥—ã:\n\n"
    
    if 'deep_context' in user_context:
        dc = user_context['deep_context']
        response += f"üéØ –¢–µ–º—ã: {', '.join(list(dc.get('current_topics', {}).keys())[:3])}\n"
        response += f"üìà –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {dc.get('emotional_arc', {}).get('current_mood', 0.5):.2f}\n"
        response += f"üèÉ –¢–µ–º–ø: {dc.get('conversation_rhythm', {}).get('pace', 'medium')}\n"
        response += f"üí≠ –í–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π: {len(dc.get('historical_topics', {}))}\n"
    
    await update.message.reply_text(response)

async def memory_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑–∞—Ç—å –ø–∞–º—è—Ç—å –æ –±–µ—Å–µ–¥–µ"""
    user_id = update.effective_user.id
    user_context = get_user_context(user_id)
    
    response = "üß† –ü–∞–º—è—Ç—å –æ –Ω–∞—à–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–∞—Ö:\n\n"
    
    if 'deep_context' in user_context:
        dc = user_context['deep_context']
        historical = list(dc.get('historical_topics', {}).keys())
        if historical:
            response += "–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ç–µ–º—ã:\n"
            for topic in historical[:5]:
                response += f"‚Ä¢ {topic}\n"
        else:
            response += "–ï—â–µ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ç–µ–º"
    
    await update.message.reply_text(response)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    if not TELEGRAM_BOT_TOKEN:
        logger.error("‚ùå TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return
    
    UserDatabase()
    
    application = (
        Application.builder()
        .token(TELEGRAM_BOT_TOKEN)
        .concurrent_updates(True)
        .build()
    )
    
    application.add_handler(CommandHandler("context", context_command))
    application.add_handler(CommandHandler("memory", memory_command))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, process_message_with_deep_context))
    application.add_error_handler(error_handler)
    
    logger.info("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –æ–±—â–µ–Ω–∏—é...")
    
    try:
        application.run_polling(
            allowed_updates=Update.ALL_TYPES,
            close_loop=False,
            stop_signals=None
        )
    except Conflict as e:
        logger.error(f"–ö–æ–Ω—Ñ–ª–∏–∫—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω: {e}")
        logger.info("–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –±–æ—Ç–∞ —á–µ—Ä–µ–∑ 5 —Å–µ–∫—É–Ω–¥...")
        time.sleep(5)
        main()
    except Exception as e:
        logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()

